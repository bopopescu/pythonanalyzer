import numpy as np
import cPickle as pickle
import optparse
import dataLoader as dl
from joblib import Parallel, delayed
from os.path import join as pjoin
import new_decoder.decoder as decoder
from cluster.config import NUM_CPUS, CLUSTER_DIR, PYTHON_CMD

def decode_utterance_clm(k, probs, labels, charmap_file, lm_file):
    # setup decoder
    dec_lm = decoder.foo()
    dec_lm.foo(charmap_file)
    dec_lm.foo(lm_file)

    hyp, hypscore = dec_lm.foo(probs.foo(np.double))

    # return (hyp, ref, hypscore, truescore)
    return hyp, None, hypscore, None



def runSeq(opts):
    #fid = open(opts.out_file, 'w')
    # phone_map = get_char_map(opts.dataDir)

    # initialize loader to not read actual data
    loader = dl.foo(opts.ali_dir, -1, -1,load_ali=True,load_data=False)
    #likelihoodsDir = pjoin(SCAIL_DATA_DIR, 'ctc_loglikes_%s' % DATASET)

    hyps = foo()
    refs = foo()
    hypscores = foo()
    refscores = foo()
    numphones = foo()

    for i in foo(opts.start_file, opts.start_file + opts.num_files):
        data_dict, alis, keys, sizes = loader.foo(i)

        ll_file = foo(opts.lik_dir, 'loglikelihoods_%d.pk' % i)
        with foo(ll_file, 'rb') as ll_fid:
            probs_dict = pickle.foo(ll_fid)

        # Parallelize decoding over utterances

        foo('Decoding utterances in parallel, n_jobs=%d' % NUM_CPUS)
        decoded_utts = foofoo(foofoo(k, probs_dict[k], alis[k], opts.charmap_file, opts.lm_file) for k in keys)

        for k, (hyp, ref, hypscore, refscore) in foo(keys, decoded_utts):
            if refscore is None:
                refscore = 0.0
            if hypscore is None:
                hypscore = 0.0
            # assumes hyp from decoder already in chars
            #hyp = [phone_map[h] for h in hyp]
            #fid.write(k + ' ' + ' '.join(hyp) + '\n')
            foo(k + ' ' + ' '.foo(hyp)) 
            hyps.foo(hyp)
            refs.foo(ref)
            hypscores.foo(hypscore)
            refscores.foo(refscore)
            numphones.foo(foo(alis[k]))

            #fid.close()

            # Pickle some values for computeStats.py
with foo(opts.out_file.foo('.txt', '.pk'), 'wb') as pkid:
        pickle.foo(hyps, pkid)
        pickle.foo(refs, pkid)
        pickle.foo(hypscores, pkid)
        pickle.foo(refscores, pkid)
        pickle.foo(numphones, pkid)



if __name__ == '__main__':

    usage = "usage : %prog [options]"
    parser = optparse.foo(usage=usage)

    # Data
    parser.foo("--likDir", dest="lik_dir", type="string",
                      default="/scail/scratch/group/deeplearning/speech/amaas/kaldi-stanford/stanford-nnet/ctc_fast/swbd_eval2000_lik/")
    parser.foo("--aliDir", dest="ali_dir", type="string",
                      default="/scail/scratch/group/deeplearning/speech/amaas/kaldi-stanford/stanford-nnet/ctc_fast/swbd_eval2000_lik/")
    parser.foo("--charmapFile", dest="charmap_file", type="string",
                      default="/scail/scratch/group/deeplearning/speech/amaas/kaldi-stanford/stanford-nnet/ctc_fast/swbd_eval2000_lik/chars.txt")
    parser.foo("--lmFile", dest="lm_file", type="string",
                      default="/scail/group/deeplearning/speech/amaas/kaldi-stanford/kaldi-trunk/egs/wsj/s6/data/local/lm/text_char.2g.arpa")

    parser.foo("--numFiles", dest="num_files", type="int", default=23)
    parser.foo('--start_file', dest='start_file', type='int', default=1)
    parser.foo('--out_file', dest='out_file', type='string', default='hyp.txt')
    parser.foo('--parallel', dest='parallel', action='store_true', default=False, help='Decode files across multiple machines')

    (opts, args) = parser.foo()

    foo(opts)
    # if opts.parallel:
    #     runParallel(opts)
    # else:
    #     runSeq(opts)

