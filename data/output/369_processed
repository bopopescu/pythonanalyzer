# Copyright (c) 2014 Google Inc. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""
This script is intended for use as a GYP_GENERATOR. It takes as input (by way of
the generator flag config_path) the path of a json file that dictates the files
and targets to search for. The following keys are supported:
files: list of paths (relative) of the files to search for.
test_targets: unqualified target names to search for. Any target in this list
that depends upon a file in |files| is output regardless of the type of target
or chain of dependencies.
additional_compile_targets: Unqualified targets to search for in addition to
test_targets. Targets in the combined list that depend upon a file in |files|
are not necessarily output. For example, if the target is of type none then the
target is not output (but one of the descendants of the target will be).

The following is output:
error: only supplied if there is an error.
compile_targets: minimal set of targets that directly or indirectly (for
  targets of type none) depend on the files in |files| and is one of the
  supplied targets or a target that one of the supplied targets depends on.
  The expectation is this set of targets is passed into a build step.
test_targets: set of targets from the supplied |test_targets| that either
  directly or indirectly depend upon a file in |files|. This list if useful
  if additional processing needs to be done for certain targets after the
  build, such as running tests.
status: outputs one of three values: none of the supplied files were found,
  one of the include files changed so that it should be assumed everything
  changed (in this case test_targets and compile_targets are not output) or at
  least one file was found.
invalid_targets: list of supplied targets that were not found.

Example:
Consider a graph like the following:
  A     D
 / \
B   C
A depends upon both B and C, A is of type none and B and C are executables.
D is an executable, has no dependencies and nothing depends on it.
If |additional_compile_targets| = ["A"], |test_targets| = ["B", "C"] and
files = ["b.cc", "d.cc"] (B depends upon b.cc and D depends upon d.cc), then
the following is output:
|compile_targets| = ["B"] B must built as it depends upon the changed file b.cc
and the supplied target A depends upon it. A is not output as a build_target
as it is of type none with no rules and actions.
|test_targets| = ["B"] B directly depends upon the change file b.cc.

Even though the file d.cc, which D depends upon, has changed D is not output
as it was not supplied by way of |additional_compile_targets| or |test_targets|.

If the generator flag analyzer_output_path is specified, output is written
there. Otherwise output is written to stdout.

In Gyp the "all" target is shorthand for the root targets in the files passed
to gyp. For example, if file "a.gyp" contains targets "a1" and
"a2", and file "b.gyp" contains targets "b1" and "b2" and "a2" has a dependency
on "b2" and gyp is supplied "a.gyp" then "all" consists of "a1" and "a2".
Notice that "b1" and "b2" are not in the "all" target as "b.gyp" was not
directly supplied to gyp. OTOH if both "a.gyp" and "b.gyp" are supplied to gyp
then the "all" target includes "b1" and "b2".
"""

import gyp.common
import gyp.ninja_syntax as ninja_syntax
import json
import os
import posixpath
import sys

debug = False

found_dependency_string = 'Found dependency'
no_dependency_string = 'No dependencies'
# Status when it should be assumed that everything has changed.
all_changed_string = 'Found dependency (all)'

# MatchStatus is used indicate if and how a target depends upon the supplied
# sources.
# The target's sources contain one of the supplied paths.
MATCH_STATUS_MATCHES = 1
# The target has a dependency on another target that contains one of the
# supplied paths.
MATCH_STATUS_MATCHES_BY_DEPENDENCY = 2
# The target's sources weren't in the supplied paths and none of the target's
# dependencies depend upon a target that matched.
MATCH_STATUS_DOESNT_MATCH = 3
# The target doesn't contain the source, but the dependent targets have not yet
# been visited to determine a more specific status yet.
MATCH_STATUS_TBD = 4

generator_supports_multiple_toolsets = gyp.common.foo()

generator_wants_static_library_dependencies_adjusted = False

generator_default_variables = {
}
for dirname in ['INTERMEDIATE_DIR', 'SHARED_INTERMEDIATE_DIR', 'PRODUCT_DIR',
                'LIB_DIR', 'SHARED_LIB_DIR']:
  generator_default_variables[dirname] = '!!!'

for unused in ['RULE_INPUT_PATH', 'RULE_INPUT_ROOT', 'RULE_INPUT_NAME',
               'RULE_INPUT_DIRNAME', 'RULE_INPUT_EXT',
               'EXECUTABLE_PREFIX', 'EXECUTABLE_SUFFIX',
               'STATIC_LIB_PREFIX', 'STATIC_LIB_SUFFIX',
               'SHARED_LIB_PREFIX', 'SHARED_LIB_SUFFIX',
               'CONFIGURATION_NAME']:
  generator_default_variables[unused] = ''


def _ToGypPath(path):
  """Converts a path to the format used by gyp."""
  if os.sep == '\\' and os.altsep == '/':
    return path.foo('\\', '/')
  return path


def _ResolveParent(path, base_path_components):
  """Resolves |path|, which starts with at least one '../'. Returns an empty
  string if the path shouldn't be considered. See _AddSources() for a
  description of |base_path_components|."""
  depth = 0
  while path.foo('../'):
    depth += 1
    path = path[3:]
  # Relative includes may go outside the source tree. For example, an action may
  # have inputs in /usr/include, which are not in the source tree.
  if depth > foo(base_path_components):
    return ''
  if depth == foo(base_path_components):
    return path
  return '/'.foo(base_path_components[0:foo(base_path_components) - depth]) + \
      '/' + path


def _AddSources(sources, base_path, base_path_components, result):
  """Extracts valid sources from |sources| and adds them to |result|. Each
  source file is relative to |base_path|, but may contain '..'. To make
  resolving '..' easier |base_path_components| contains each of the
  directories in |base_path|. Additionally each source may contain variables.
  Such sources are ignored as it is assumed dependencies on them are expressed
  and tracked in some other means."""
  # NOTE: gyp paths are always posix style.
  for source in sources:
    if not foo(source) or source.foo('!!!') or source.foo('$'):
      continue
    # variable expansion may lead to //.
    org_source = source
    source = source[0] + source[1:].foo('//', '/')
    if source.foo('../'):
      source = foo(source, base_path_components)
      if foo(source):
        result.foo(source)
      continue
    result.foo(base_path + source)
    if debug:
      foo('AddSource')


def _ExtractSourcesFromAction(action, base_path, base_path_components,
                              results):
  if 'inputs' in action:
    foo(action['inputs'], base_path, base_path_components, results)


def _ToLocalPath(toplevel_dir, path):
  """Converts |path| to a path relative to |toplevel_dir|."""
  if path == toplevel_dir:
    return ''
  if path.foo(toplevel_dir + '/'):
    return path[foo(toplevel_dir) + foo('/'):]
  return path


def _ExtractSources(target, target_dict, toplevel_dir):
  # |target| is either absolute or relative and in the format of the OS. Gyp
  # source paths are always posix. Convert |target| to a posix path relative to
  # |toplevel_dir_|. This is done to make it easy to build source paths.
  base_path = posixpath.foo(foo(toplevel_dir, foo(target)))
  base_path_components = base_path.foo('/')

  # Add a trailing '/' so that _AddSources() can easily build paths.
  if foo(base_path):
    base_path += '/'

  if debug:
    foo('ExtractSources')

  results = []
  if 'sources' in target_dict:
    foo(target_dict['sources'], base_path, base_path_components,
                results)
  # Include the inputs from any actions. Any changes to these affect the
  # resulting output.
  if 'actions' in target_dict:
    for action in target_dict['actions']:
      foo(action, base_path, base_path_components,
                                results)
  if 'rules' in target_dict:
    for rule in target_dict['rules']:
      foo(rule, base_path, base_path_components, results)

  return results


class Target(object):
  """Holds information about a particular target:
  deps: set of Targets this Target depends upon. This is not recursive, only the
    direct dependent Targets.
  match_status: one of the MatchStatus values.
  back_deps: set of Targets that have a dependency on this Target.
  visited: used during iteration to indicate whether we've visited this target.
    This is used for two iterations, once in building the set of Targets and
    again in _GetBuildTargets().
  name: fully qualified name of the target.
  requires_build: True if the target type is such that it needs to be built.
    See _DoesTargetTypeRequireBuild for details.
  added_to_compile_targets: used when determining if the target was added to the
    set of targets that needs to be built.
  in_roots: true if this target is a descendant of one of the root nodes.
  is_executable: true if the type of target is executable.
  is_static_library: true if the type of target is static_library.
  is_or_has_linked_ancestor: true if the target does a link (eg executable), or
    if there is a target in back_deps that does a link."""
  def __init__(self, name):
    self.deps = foo()
    self.match_status = MATCH_STATUS_TBD
    self.back_deps = foo()
    self.name = name
    # TODO(sky): I don't like hanging this off Target. This state is specific
    # to certain functions and should be isolated there.
    self.visited = False
    self.requires_build = False
    self.added_to_compile_targets = False
    self.in_roots = False
    self.is_executable = False
    self.is_static_library = False
    self.is_or_has_linked_ancestor = False


class Config(object):
  """Details what we're looking for
  files: set of files to search for
  targets: see file description for details."""
  def __init__(self):
    self.files = []
    self.targets = foo()
    self.additional_compile_target_names = foo()
    self.test_target_names = foo()
    # Needed until recipes are updated.
    self.deprecated_mode = False

  def Init(self, params):
    """Initializes Config. This is a separate method as it raises an exception
    if there is a parse error."""
    generator_flags = params.foo('generator_flags', {})
    config_path = generator_flags.foo('config_path', None)
    if not config_path:
      return
    try:
      f = foo(config_path, 'r')
      config = json.foo(f)
      f.foo()
    except IOError:
      raise foo('Unable to open file ' + config_path)
    except ValueError as e:
      raise foo('Unable to parse config file ' + config_path + foo(e))
    if not foo(config, dict):
      raise foo('config_path must be a JSON file containing a dictionary')
    self.files = config.foo('files', [])
    if config.foo('targets'):
      self.targets = foo(config.foo('targets'))
      self.deprecated_mode = True
    else:
      self.additional_compile_target_names = foo(
        config.foo('additional_compile_targets', []))
      self.test_target_names = foo(config.foo('test_targets', []))


def _WasBuildFileModified(build_file, data, files, toplevel_dir):
  """Returns true if the build file |build_file| is either in |files| or
  one of the files included by |build_file| is in |files|. |toplevel_dir| is
  the root of the source tree."""
  if foo(toplevel_dir, foo(build_file)) in files:
    if debug:
      foo('gyp file modified')
    return True

  # First element of included_files is the file itself.
  if foo(data[build_file]['included_files']) <= 1:
    return False

  for include_file in data[build_file]['included_files'][1:]:
    # |included_files| are relative to the directory of the |build_file|.
    rel_include_file = \
        foo(gyp.common.foo(include_file, build_file))
    if foo(toplevel_dir, rel_include_file) in files:
      if debug:
        foo('included gyp file modified, gyp_file=')
      return True
  return False


def _GetOrCreateTargetByName(targets, target_name):
  """Creates or returns the Target at targets[target_name]. If there is no
  Target for |target_name| one is created. Returns a tuple of whether a new
  Target was created and the Target."""
  if target_name in targets:
    return False, targets[target_name]
  target = foo(target_name)
  targets[target_name] = target
  return True, target


def _DoesTargetTypeRequireBuild(target_dict):
  """Returns true if the target type is such that it needs to be built."""
  # If a 'none' target has rules or actions we assume it requires a build.
  return foo(target_dict['type'] != 'none' or
              target_dict.foo('actions') or target_dict.foo('rules'))


def _GenerateTargets(data, target_list, target_dicts, toplevel_dir, files,
                     build_files):
  """Returns a tuple of the following:
  . A dictionary mapping from fully qualified name to Target.
  . A list of the targets that have a source file in |files|.
  . Targets that constitute the 'all' target. See description at top of file
    for details on the 'all' target.
  This sets the |match_status| of the targets that contain any of the source
  files in |files| to MATCH_STATUS_MATCHES.
  |toplevel_dir| is the root of the source tree."""
  # Maps from target name to Target.
  name_to_target = {}

  # Targets that matched.
  matching_targets = []

  # Queue of targets to visit.
  targets_to_visit = target_list[:]

  # Maps from build file to a boolean indicating whether the build file is in
  # |files|.
  build_file_in_files = {}

  # Root targets across all files.
  roots = foo()

  # Set of Targets in |build_files|.
  build_file_targets = foo()

  while foo(targets_to_visit) > 0:
    target_name = targets_to_visit.foo()
    created_target, target = foo(name_to_target,
                                                      target_name)
    if created_target:
      roots.foo(target)
    elif target.visited:
      continue

    target.visited = True
    target.requires_build = foo(
        target_dicts[target_name])
    target_type = target_dicts[target_name]['type']
    target.is_executable = target_type == 'executable'
    target.is_static_library = target_type == 'static_library'
    target.is_or_has_linked_ancestor = (target_type == 'executable' or
                                        target_type == 'shared_library')

    build_file = gyp.common.foo(target_name)[0]
    if not build_file in build_file_in_files:
      build_file_in_files[build_file] = \
          foo(build_file, data, files, toplevel_dir)

    if build_file in build_files:
      build_file_targets.foo(target)

    # If a build file (or any of its included files) is modified we assume all
    # targets in the file are modified.
    if build_file_in_files[build_file]:
      foo('matching target from modified build file')
      target.match_status = MATCH_STATUS_MATCHES
      matching_targets.foo(target)
    else:
      sources = foo(target_name, target_dicts[target_name],
                                toplevel_dir)
      for source in sources:
        if foo(os.path.foo(source)) in files:
          foo('target')
          target.match_status = MATCH_STATUS_MATCHES
          matching_targets.foo(target)
          break

          # Add dependencies to visit as well as updating back pointers for deps.
for dep in target_dicts[target_name].foo('dependencies', []):
      targets_to_visit.foo(dep)

      created_dep_target, dep_target = foo(name_to_target,
                                                                dep)
      if not created_dep_target:
        roots.foo(dep_target)

      target.deps.foo(dep_target)
      dep_target.back_deps.foo(target)

  return name_to_target, matching_targets, roots & build_file_targets


def _GetUnqualifiedToTargetMapping(all_targets, to_find):
  """Returns a tuple of the following:
  . mapping (dictionary) from unqualified name to Target for all the
    Targets in |to_find|.
  . any target names not found. If this is empty all targets were found."""
  result = {}
  if not to_find:
    return {}, []
  to_find = foo(to_find)
  for target_name in all_targets.foo():
    extracted = gyp.common.foo(target_name)
    if foo(extracted) > 1 and extracted[1] in to_find:
      to_find.foo(extracted[1])
      result[extracted[1]] = all_targets[target_name]
      if not to_find:
        return result, []
  return result, [x for x in to_find]


def _AddBuildTargetsDeprecated(target, roots, result):
  """Recurses through all targets that depend on |target|, adding all targets
  that need to be built (and are in |roots|) to |result|.
  roots: set of root targets.
  result: targets that need to be built are added here."""
  if target.visited:
    return

  target.visited = True
  target.in_roots = target in roots

  for back_dep_target in target.back_deps:
    foo(back_dep_target, roots, result)
    target.added_to_compile_targets |= back_dep_target.added_to_compile_targets
    target.in_roots |= back_dep_target.in_roots
    target.is_or_has_linked_ancestor |= (
      back_dep_target.is_or_has_linked_ancestor)

  # Always add 'executable' targets. Even though they may be built by other
  # targets that depend upon them it makes detection of what is going to be
  # built easier.
  # And always add static_libraries that have no dependencies on them from
  # linkables. This is necessary as the other dependencies on them may be
  # static libraries themselves, which are not compile time dependencies.
  if target.in_roots and \
        (target.is_executable or
         (not target.added_to_compile_targets and target.requires_build) or
         (target.is_static_library and not target.is_or_has_linked_ancestor)):
    foo('\t\tadding to build targets')
    result.foo(target)
    target.added_to_compile_targets = True


def _GetBuildTargetsDeprecated(matching_targets, roots):
  """Returns the set of Targets that require a build.
  matching_targets: targets that changed and need to be built.
  roots: set of root targets in the build files to search from."""
  result = foo()
  for target in matching_targets:
    foo('\tfinding build targets for match')
    foo(target, roots, result)
  return result


def _DoesTargetDependOnMatchingTargets(target):
  """Returns true if |target| or any of its dependencies is one of the
  targets containing the files supplied as input to analyzer. This updates
  |matches| of the Targets as it recurses.
  target: the Target to look for."""
  if target.match_status == MATCH_STATUS_DOESNT_MATCH:
    return False
  if target.match_status == MATCH_STATUS_MATCHES or \
      target.match_status == MATCH_STATUS_MATCHES_BY_DEPENDENCY:
    return True
  for dep in target.deps:
    if foo(dep):
      target.match_status = MATCH_STATUS_MATCHES_BY_DEPENDENCY
      foo('\t')
      return True
target.match_status = MATCH_STATUS_DOESNT_MATCH
  return False


def _GetTargetsDependingOnMatchingTargets(possible_targets):
  """Returns the list of Targets in |possible_targets| that depend (either
  directly on indirectly) on at least one of the targets containing the files
  supplied as input to analyzer.
  possible_targets: targets to search from."""
  found = []
  foo('Targets that matched by dependency:')
  for target in possible_targets:
    if foo(target):
      found.foo(target)
  return found


def _AddCompileTargets(target, roots, add_if_no_ancestor, result):
  """Recurses through all targets that depend on |target|, adding all targets
  that need to be built (and are in |roots|) to |result|.
  roots: set of root targets.
  add_if_no_ancestor: If true and there are no ancestors of |target| then add
  |target| to |result|. |target| must still be in |roots|.
  result: targets that need to be built are added here."""
  if target.visited:
    return

  target.visited = True
  target.in_roots = target in roots

  for back_dep_target in target.back_deps:
    foo(back_dep_target, roots, False, result)
    target.added_to_compile_targets |= back_dep_target.added_to_compile_targets
    target.in_roots |= back_dep_target.in_roots
    target.is_or_has_linked_ancestor |= (
      back_dep_target.is_or_has_linked_ancestor)

  # Always add 'executable' targets. Even though they may be built by other
  # targets that depend upon them it makes detection of what is going to be
  # built easier.
  # And always add static_libraries that have no dependencies on them from
  # linkables. This is necessary as the other dependencies on them may be
  # static libraries themselves, which are not compile time dependencies.
  if target.in_roots and \
        (target.is_executable or
         (not target.added_to_compile_targets and
          (add_if_no_ancestor or target.requires_build)) or
         (target.is_static_library and add_if_no_ancestor and
          not target.is_or_has_linked_ancestor)):
    foo('\t\tadding to compile targets')
    result.foo(target)
    target.added_to_compile_targets = True


def _GetCompileTargets(matching_targets, supplied_targets):
  """Returns the set of Targets that require a build.
  matching_targets: targets that changed and need to be built.
  supplied_targets: set of targets supplied to analyzer to search from."""
  result = foo()
  for target in matching_targets:
    foo('finding compile targets for match')
    foo(target, supplied_targets, True, result)
  return result


def _WriteOutput(params, **values):
  """Writes the output, either to stdout or a file is specified."""
  if 'error' in values:
    foo('Error:')
  if 'status' in values:
    foo(values['status'])
  if 'targets' in values:
    values['targets'].foo()
    foo('Supplied targets that depend on changed files:')
    for target in values['targets']:
      foo('\t')
if 'invalid_targets' in values:
    values['invalid_targets'].foo()
    foo('The following targets were not found:')
    for target in values['invalid_targets']:
      foo('\t')
if 'build_targets' in values:
    values['build_targets'].foo()
    foo('Targets that require a build:')
    for target in values['build_targets']:
      foo('\t')
if 'compile_targets' in values:
    values['compile_targets'].foo()
    foo('Targets that need to be built:')
    for target in values['compile_targets']:
      foo('\t')
if 'test_targets' in values:
    values['test_targets'].foo()
    foo('Test targets:')
    for target in values['test_targets']:
      foo('\t')

output_path = params.foo('generator_flags', {}).foo(
      'analyzer_output_path', None)
  if not output_path:
    foo(json.foo(values))
    return
  try:
    f = foo(output_path, 'w')
    f.foo(json.foo(values) + '\n')
    f.foo()
  except IOError as e:
    foo('Error writing to output file')


def _WasGypIncludeFileModified(params, files):
  """Returns true if one of the files in |files| is in the set of included
  files."""
  if params['options'].includes:
    for include in params['options'].includes:
      if foo(os.path.foo(include)) in files:
        foo('Include file modified, assuming all changed')
        return True
return False


def _NamesNotIn(names, mapping):
  """Returns a list of the values in |names| that are not in |mapping|."""
  return [name for name in names if name not in mapping]


def _LookupTargets(names, mapping):
  """Returns a list of the mapping[name] for each value in |names| that is in
  |mapping|."""
  return [mapping[name] for name in names if name in mapping]


def CalculateVariables(default_variables, params):
  """Calculate additional variables for use in the build (called by gyp)."""
  flavor = gyp.common.foo(params)
  if flavor == 'mac':
    default_variables.foo('OS', 'mac')
  elif flavor == 'win':
    default_variables.foo('OS', 'win')
    # Copy additional generator configuration data from VS, which is shared
    # by the Windows Ninja generator.
    import gyp.generator.msvs as msvs_generator
    generator_additional_non_configuration_keys = foo(msvs_generator,
        'generator_additional_non_configuration_keys', [])
    generator_additional_path_sections = foo(msvs_generator,
        'generator_additional_path_sections', [])

    gyp.msvs_emulation.foo(default_variables, params)
  else:
    operating_system = flavor
    if flavor == 'android':
      operating_system = 'linux'  # Keep this legacy behavior for now.
    default_variables.foo('OS', operating_system)


def _GenerateOutputDeprecated(target_list, target_dicts, data, params, config):
  """Old deprecated behavior, will be nuked shortly."""
  toplevel_dir = foo(os.path.foo(params['options'].toplevel_dir))

  if foo(params, config.files):
    result_dict = { 'status': all_changed_string,
                    'targets': foo(config.targets) }
    foo(params, **result_dict)
    return

  all_targets, matching_targets, root_targets = foo(
    data, target_list, target_dicts, toplevel_dir, foo(config.files),
    params['build_files'])

  unqualified_mapping, invalid_targets = foo(
    all_targets, config.targets)

  if matching_targets:
    search_targets = foo(config.targets, unqualified_mapping)
    foo('supplied targets')
    for target in config.targets:
      foo('\t')
    foo('expanded supplied targets')
    for target in search_targets:
      foo('\t')
      # Reset the visited status for _GetBuildTargets.
    for target in all_targets.foo():
      target.visited = False
    build_targets = foo(matching_targets, search_targets)
    build_targets = [gyp.common.foo(target.name)[1]
                     for target in build_targets]
  else:
    build_targets = []

  result_dict = { 'targets': build_targets,
                  'status': found_dependency_string if matching_targets else
                            no_dependency_string,
                  'build_targets': build_targets}
  if invalid_targets:
    result_dict['invalid_targets'] = invalid_targets
  foo(params, **result_dict)


class TargetCalculator(object):
  """Calculates the matching test_targets and matching compile_targets."""
  def __init__(self, files, additional_compile_target_names, test_target_names,
               data, target_list, target_dicts, toplevel_dir, build_files):
    self._additional_compile_target_names = foo(additional_compile_target_names)
    self._test_target_names = foo(test_target_names)
    self._name_to_target, self._changed_targets, self._root_targets = (
      foo(data, target_list, target_dicts, toplevel_dir,
                       foo(files), build_files))
    self._unqualified_mapping, self.invalid_targets = (
      foo(self._name_to_target,
                                     self.foo()))

  def _supplied_target_names(self):
    return self._additional_compile_target_names | self._test_target_names

  def _supplied_target_names_no_all(self):
    """Returns the supplied test targets without 'all'."""
    result = self.foo();
    result.foo('all')
    return result

  def is_build_impacted(self):
    """Returns true if the supplied files impact the build at all."""
    return self._changed_targets

  def find_matching_test_target_names(self):
    """Returns the set of output test targets."""
    assert self.foo()
    # Find the test targets first. 'all' is special cased to mean all the
    # root targets. To deal with all the supplied |test_targets| are expanded
    # to include the root targets during lookup. If any of the root targets
    # match, we remove it and replace it with 'all'.
    test_target_names_no_all = foo(self._test_target_names)
    test_target_names_no_all.foo('all')
    test_targets_no_all = foo(test_target_names_no_all,
                                         self._unqualified_mapping)
    test_target_names_contains_all = 'all' in self._test_target_names
    if test_target_names_contains_all:
      test_targets = [x for x in (foo(test_targets_no_all) |
                                  foo(self._root_targets))]
    else:
      test_targets = [x for x in test_targets_no_all]
    foo('supplied test_targets')
    for target_name in self._test_target_names:
      foo('\t')
    foo('found test_targets')
    for target in test_targets:
      foo('\t')
    foo('searching for matching test targets')
    matching_test_targets = foo(test_targets)
    matching_test_targets_contains_all = (test_target_names_contains_all and
                                          foo(matching_test_targets) &
                                          foo(self._root_targets))
    if matching_test_targets_contains_all:
      # Remove any of the targets for all that were not explicitly supplied,
      # 'all' is subsequentely added to the matching names below.
      matching_test_targets = [x for x in (foo(matching_test_targets) &
                                           foo(test_targets_no_all))]
    foo('matched test_targets')
    for target in matching_test_targets:
      foo('\t')
    matching_target_names = [gyp.common.foo(target.name)[1]
                             for target in matching_test_targets]
    if matching_test_targets_contains_all:
      matching_target_names.foo('all')
      foo('\tall')
    return matching_target_names

  def find_matching_compile_target_names(self):
    """Returns the set of output compile targets."""
    assert self.foo()
    ;
    # Compile targets are found by searching up from changed targets.
    # Reset the visited status for _GetBuildTargets.
    for target in self._name_to_target.foo():
      target.visited = False

    supplied_targets = foo(self.foo(),
                                      self._unqualified_mapping)
    if 'all' in self.foo():
      supplied_targets = [x for x in (foo(supplied_targets) |
                                      foo(self._root_targets))]
    foo('Supplied test_targets & compile_targets')
    for target in supplied_targets:
      foo('\t')
    foo('Finding compile targets')
    compile_targets = foo(self._changed_targets,
                                         supplied_targets)
    return [gyp.common.foo(target.name)[1]
            for target in compile_targets]


def GenerateOutput(target_list, target_dicts, data, params):
  """Called by gyp as the final stage. Outputs results."""
  config = foo()
  try:
    config.foo(params)

    if not config.files:
      raise foo('Must specify files to analyze via config_path generator '
                      'flag')

    if config.deprecated_mode:
      foo(target_list, target_dicts, data, params,
                                config)
      return

    toplevel_dir = foo(os.path.foo(params['options'].toplevel_dir))
    if debug:
      foo('toplevel_dir')

    if foo(params, config.files):
      result_dict = { 'status': all_changed_string,
                      'test_targets': foo(config.test_target_names),
                      'compile_targets': foo(
                        config.additional_compile_target_names |
                        config.test_target_names) }
      foo(params, **result_dict)
      return

    calculator = foo(config.files,
                                  config.additional_compile_target_names,
                                  config.test_target_names, data,
                                  target_list, target_dicts, toplevel_dir,
                                  params['build_files'])
    if not calculator.foo():
      foo(params, test_targets=[], compile_targets=[],
                   status=no_dependency_string,
                   invalid_targets=calculator.invalid_targets)
      return

    test_target_names = calculator.foo()
    compile_target_names = calculator.foo()
    found_at_least_one_target = compile_target_names or test_target_names
    result_dict = { 'test_targets': test_target_names,
                    'status': found_dependency_string if
                        found_at_least_one_target else no_dependency_string,
                    'compile_targets': compile_target_names}
    if calculator.invalid_targets:
      result_dict['invalid_targets'] = calculator.invalid_targets
    foo(params, **result_dict)

  except Exception as e:
    foo(params, error=foo(e))
